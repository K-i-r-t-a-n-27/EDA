{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9185419",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy matplotlib seaborn skilit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2be15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Load the datasets\n",
    "wine_df = pd.read_csv(\"WineQT.csv\")\n",
    "student_df = pd.read_csv(\"student_data.csv\")\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "display(wine_df.head(), student_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2b2add",
   "metadata": {},
   "source": [
    "1: Key Features of the Wine Quality Dataset\n",
    "The Wine Quality Dataset consists of several chemical properties that influence the taste, texture, and overall quality of the wine. Each feature represents a different chemical characteristic, such as acidity, sugar content, or alcohol percentage, all of which contribute to the final quality rating. For example, fixed acidity affects the wine’s tartness, while volatile acidity influences the vinegar-like aroma. Similarly, residual sugar impacts the wine's sweetness, and alcohol content often has a strong correlation with perceived quality. Understanding these features is essential in predicting wine quality, as each plays a role in shaping the sensory experience of the wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970fe91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display column names\n",
    "print(\"Wine Quality Dataset Columns:\", wine_df.columns.tolist())\n",
    "\n",
    "# Display basic statistics\n",
    "print(wine_df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c16060c",
   "metadata": {},
   "source": [
    "2: Handling Missing Data in Wine Quality Dataset\n",
    "Handling missing data is crucial in any dataset to ensure the accuracy and reliability of the analysis. In the Wine Quality Dataset, missing values can arise due to incomplete measurements or data collection errors. Various imputation techniques can be used to handle these missing values. Mean imputation replaces missing values with the average of that feature, preserving the overall distribution but potentially distorting relationships. Median imputation is useful for skewed data, while mode imputation works best for categorical features. Advanced techniques like K-Nearest Neighbors (KNN) imputation can predict missing values based on the nearest data points, but they require more computation. The choice of imputation technique depends on the dataset characteristics and the impact of missing values on the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc565f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values in Wine Dataset:\\n\", wine_df.isnull().sum())\n",
    "\n",
    "# Apply mean imputation\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "wine_df_imputed = pd.DataFrame(imputer.fit_transform(wine_df), columns=wine_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe55c71c",
   "metadata": {},
   "source": [
    "3: Key Factors Affecting Student Performance in Exams\n",
    "Student performance is influenced by multiple factors, including academic preparation, parental support, and personal study habits. One of the most effective ways to analyze these factors is through correlation analysis, which identifies relationships between different variables. For instance, a strong positive correlation between study time and exam scores suggests that students who study more tend to perform better. Similarly, parental education level might influence a student’s academic success, as parents with higher education may provide better guidance and resources. By visualizing these relationships using a correlation heatmap, we can determine which factors have the most significant impact on student performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a232a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display column names\n",
    "print(\"Student Performance Dataset Columns:\", student_df.columns.tolist())\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(student_df.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix of Student Performance Data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257ad775",
   "metadata": {},
   "source": [
    "4: Feature Engineering for Student Performance Dataset\n",
    "Feature engineering is a crucial step in preparing data for analysis, as it involves creating new features or transforming existing ones to improve model performance. In the Student Performance Dataset, we can enhance our analysis by creating a new feature called \"average_score\", which represents the mean of math, reading, and writing scores. This provides a single metric to evaluate overall student performance rather than analyzing each subject separately. Additionally, categorical variables such as gender, parental education, and test preparation course completion might need to be converted into numerical values through one-hot encoding to make them useful for machine learning models. These transformations help in improving data interpretability and ensuring better predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327695d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature for overall performance\n",
    "student_df[\"average_score\"] = student_df[[\"math_score\", \"reading_score\", \"writing_score\"]].mean()\n",
    "\n",
    "# Display the first few rows with the new feature\n",
    "display(student_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5931ec5",
   "metadata": {},
   "source": [
    "5: Exploratory Data Analysis (EDA) on Wine Quality Dataset\n",
    "EDA helps us understand the distribution of features and identify potential data issues. By plotting histograms of different features, we can observe their spread and detect any skewness in the dataset. Many features in the Wine Quality Dataset exhibit skewed distributions, meaning they do not follow a normal bell-shaped curve. This non-normality can impact the performance of certain statistical and machine learning models, which assume normally distributed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3125dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms to check feature distribution\n",
    "plt.figure(figsize=(12,6))\n",
    "wine_df.hist(bins=30, figsize=(12,8), layout=(3,4))\n",
    "plt.suptitle(\"Feature Distribution in Wine Quality Dataset\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f484edab",
   "metadata": {},
   "source": [
    "Identifying Non-Normal Features\n",
    "To quantify skewness, we calculate the skewness values for each feature. A high skewness value (greater than ±1) indicates a strong deviation from normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce53eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check skewness of features\n",
    "skewness = wine_df.skew()\n",
    "print(\"Skewness of Features:\\n\", skewness)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5e83c3",
   "metadata": {},
   "source": [
    "Applying Transformations to Improve Normality\n",
    "When a dataset has skewed features, applying transformations can help normalize the data. One effective method is the Power Transformation, which stabilizes variance and makes the distribution more Gaussian-like. This transformation improves the performance of machine learning models that assume normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbfa877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Power Transformation to normalize skewed features\n",
    "pt = PowerTransformer()\n",
    "wine_df_transformed = pd.DataFrame(pt.fit_transform(wine_df), columns=wine_df.columns)\n",
    "\n",
    "# Visualize transformed features\n",
    "plt.figure(figsize=(12,6))\n",
    "wine_df_transformed.hist(bins=30, figsize=(12,8), layout=(3,4))\n",
    "plt.suptitle(\"Transformed Feature Distribution\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
